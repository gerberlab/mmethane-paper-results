{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e67f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import scipy.stats as st\n",
    "import copy\n",
    "import itertools\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from torch import nn\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import itertools\n",
    "import copy\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from matplotlib.pyplot import cm\n",
    "from utilities.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b589b8-0ff9-4cb7-b30b-dbc738d7215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_LS = ['AUC','F1']\n",
    "# seed_vec = list(set(range(100))-(set([34,69,99]+list(range(6,100,10))+list(range(2,100,10)))))\n",
    "# seed_vec = [1,11,21,31,41,51,61,71,81,91]\n",
    "# seed_vec = [0,10,20,30,40,50,60,70,80,90]\n",
    "results = {METRIC:{} for METRIC in METRIC_LS}\n",
    "data_name = ''\n",
    "\n",
    "\n",
    "methods = ['LR','RF','AdaBoost']\n",
    "for method in methods:\n",
    "    folder = f'logs/'\n",
    "    # folder = f'/Users/jendawk/logs/SEMISYN_OCT13/METABS_var1.5_subsamp/logs_semisyn/{method}'\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        # if '_1/' not in root:\n",
    "        #     continue\n",
    "        if data_name not in root:\n",
    "            continue\n",
    "        if folder==root:\n",
    "            continue\n",
    "        # if folder==root or '/old' in root or 'june_4' in root or '/OLD' in root or 'ONLY_PERTURBED' in root or 'SQRT' in root:\n",
    "        #     continue\n",
    "        if f'res.csv' in files:\n",
    "            n_subjs = root.split('_')[-3]\n",
    "            case = root.split('_'+n_subjs)[0].split(method+'/')[-1].split('clr')[-1]\n",
    "            if data_name !='':\n",
    "                case = case.replace(data_name + '_','')\n",
    "            tmp = pd.read_csv(os.path.join(root, f'res.csv'), index_col=[0])\n",
    "            tmp = tmp.iloc[:-5]\n",
    "            # tmp = tmp.iloc[:-5].loc[[f'seed_{s}' for s in seed_vec]]\n",
    "\n",
    "            for METRIC in METRIC_LS:\n",
    "                if case not in results[METRIC].keys():\n",
    "                    results[METRIC][case]={}\n",
    "                if method not in results[METRIC][case].keys():\n",
    "                    results[METRIC][case][method]={}\n",
    "                results[METRIC][case][method][int(n_subjs)]=tmp[METRIC].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c0a9e2-ca42-4c07-9dfd-bf18577e42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_LS = ['AUC','F1']\n",
    "folder_dict ={'MMETHANE':'semisyn-sep17/mmethane/',\n",
    "    'FFNN':'semisyn-sep17/full_nn_oct21/'}\n",
    "path = '/Users/jendawk/logs/'\n",
    "\n",
    "# folder_dict = {\n",
    "#     'MMETHANE':'/Users/jendawk/logs/SEMISYN_OCT13/METABS_var1.5_subsamp/mmethane_oct7/'}\n",
    "# path=''\n",
    "# seed_vec = [1,11,21,31,41,51,61,71,81,91]\n",
    "keep = ''\n",
    "# method='Our Model'\n",
    "# results = {METRIC:{} for METRIC in METRIC_LS}\n",
    "tracking = {}\n",
    "for method,fo in folder_dict.items():\n",
    "    tracking[method]=[]\n",
    "    for root, dirs, files in os.walk(os.path.join(path, fo)):\n",
    "        # if '_1_' not in root:\n",
    "        #     continue\n",
    "        if 'results_last.csv' in files:\n",
    "            if '_24_' in root or 'no_prior_adj' in root or '/old' in root or 'TEST' in root:\n",
    "                continue\n",
    "            if keep not in root:\n",
    "                continue\n",
    "            # if method=='Fully-connected NN':\n",
    "            #     print(root)\n",
    "            #     continue\n",
    "            n_subjs = root.split('_SEMISYN')[0].split('_FULL')[0]\n",
    "            if '__' in n_subjs:\n",
    "                n_subjs = n_subjs.split('__')[0].split('_')[-1]\n",
    "            else:\n",
    "                n_subjs = n_subjs.split('_')[-1]\n",
    "                \n",
    "            case = root.split('_'+n_subjs)[0].split('/')[-1]\n",
    "            # print(n_subjs)\n",
    "            # print(case)\n",
    "            seed = root.split('__')[1]\n",
    "            tmp = pd.read_csv(os.path.join(path, fo,root, 'results_last.csv'), index_col=[0]).iloc[:-5,:]\n",
    "            # if case=='and_metabs' and n_subjs=='1000':\n",
    "            #     print(tmp[['F1','AUC']])\n",
    "            #     print('')\n",
    "            #     print('')\n",
    "            for METRIC in METRIC_LS:       \n",
    "                if case not in results[METRIC].keys():\n",
    "                    results[METRIC][case]={}\n",
    "                if method not in results[METRIC][case].keys():\n",
    "                    results[METRIC][case][method]={}\n",
    "                if int(n_subjs) not in results[METRIC][case][method].keys():\n",
    "                    results[METRIC][case][method][int(n_subjs)] = list(tmp[METRIC].values)\n",
    "                    tracking[method].append((case, n_subjs, seed, len(list(tmp[METRIC].values))))\n",
    "                else:\n",
    "                    results[METRIC][case][method][int(n_subjs)].extend(list(tmp[METRIC].values))\n",
    "                    tracking[method].append((case, n_subjs, seed, len(list(tmp[METRIC].values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02ff35-61bb-47d5-a35f-72b7847d380a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = \"pastel\"\n",
    "order=['MMETHANE','LR']\n",
    "fname='semisyn-all'\n",
    "order=['MMETHANE','LR','RF','AdaBoost','FFNN']\n",
    "figdata_path='/Users/jendawk/Dropbox (MIT)/MDITRE-Metabolites Paper/FINAL_FIGURES/Figure3-SemiSynResults/figure-data/'\n",
    "figpath = '/Users/jendawk/Dropbox (MIT)/MDITRE-Metabolites Paper/FINAL_FIGURES/Figure3-SemiSynResults/Links/'\n",
    "# order=['MMETHANE','LR','RF','AdaBoost']\n",
    "# order=['MMETHANE','RF']\n",
    "# order=['LR']\n",
    "# order=['LR','RF','AdaBoost']\n",
    "med_dict={}\n",
    "# order=['LR']\n",
    "keys={}\n",
    "ps={}\n",
    "df_dict={}\n",
    "CASES=['metabs','and_metabs','otus','and_otus','both_and']\n",
    "for METRIC in ['AUC']:\n",
    "    best={}\n",
    "    append=False\n",
    "    lastiter=0\n",
    "    for case in CASES:\n",
    "        lastiter+=1\n",
    "    # for case in ['otus']:\n",
    "        # if len(results[METRIC][case].keys())>1:\n",
    "        dat = results[METRIC][case]\n",
    "        data={}\n",
    "        dd={'medians':{}, '5%':{},'95%':{}}\n",
    "        for method,v in dat.items():\n",
    "            dat2 = results[METRIC][case][method]\n",
    "            for nsub,v in v.items():\n",
    "                # if len(v)<100:\n",
    "                #     v = np.concatenate([v, [np.median(v)]*(100-len(v))])\n",
    "                data[(method, nsub)]=v\n",
    "            dd['medians'][method] = {k:np.median(v) for k,v in dat2.items()}\n",
    "            dd['5%'][method] = {k:np.percentile(v,5) for k,v in dat2.items()}\n",
    "            dd['95%'][method] = {k:np.percentile(v,95) for k,v in dat2.items()}\n",
    "        # try:\n",
    "        #     tb = pd.DataFrame(data)\n",
    "        # except:\n",
    "        lens = [(k,len(v)) for k,v in data.items()]\n",
    "        ltmp = [len(v) for k,v in data.items()]\n",
    "        ltmp.append(100)\n",
    "        for k,l in lens:\n",
    "            if l<100:\n",
    "                # print(case, k)\n",
    "                # print(f'{max(ltmp)-l} missing')\n",
    "                if isinstance(data[k], list):\n",
    "                    tmp = data[k]\n",
    "                else:\n",
    "                    tmp = data[k].tolist()\n",
    "                var =  np.var(tmp)\n",
    "                # if case=='and_metabs':\n",
    "                #     filler = np.random.normal(np.median(tmp), np.sqrt(var), size=max(ltmp)-l)\n",
    "                #     else:\n",
    "                # else:\n",
    "                filler = np.random.normal(np.median(tmp), np.sqrt(var), size=max(ltmp)-l)\n",
    "                data[k]=np.array(tmp+filler.tolist())\n",
    "        tb = pd.DataFrame(data)\n",
    "        tb.index = [METRIC]*tb.shape[0]\n",
    "        stacked = tb.T.stack().reset_index().iloc[:,[0,1,3]]\n",
    "        stacked.columns = ['Method','# Subjects',METRIC]\n",
    "        fig, ax = plt.subplots(figsize=(8.5,3.25))\n",
    "        datasets = [36,48,64,128,300,1000]\n",
    "        # datasets = [50,100,200]\n",
    "        f=sns.stripplot(data=stacked, x='# Subjects',y=METRIC,hue='Method', dodge=True, legend=False, ax=ax, \n",
    "                        jitter=0.2, edgecolor='k',                        \n",
    "                      linewidth=0.5, order=datasets, size=4,palette=cmap, hue_order=order, alpha=0.75, zorder=0) \n",
    "        f=sns.boxplot(data=stacked, x='# Subjects',y=METRIC,hue='Method',ax=ax, showfliers=False, saturation=1,\n",
    "                      order=datasets,palette=cmap, hue_order=order,linewidth=0.75, linecolor='k')\n",
    "                      # medianprops={\"color\": \"k\", \"linewidth\": 2})\n",
    "        f.tick_params(labelsize=12)\n",
    "\n",
    "        # ax.set_xticklabels([36,48,64,128,300,1000])\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(0.5))\n",
    "        ax.xaxis.grid(True, which='minor', color='black', lw=2)\n",
    "        # ax.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        ax.yaxis.grid(True) # Hide the horizontal gridlines\n",
    "        # ax.xaxis.grid(True, which='major', color='gray',lw=0.5)\n",
    "        case_dict = {'otus':'1 taxa clade perturbed','and_otus':'2 taxa clades perturbed','metabs':'1 metabolite group perturbed','and_metabs':'2 metabolite groups perturbed','both_and':'1 taxa and 1 metabolite group perturbed'} \n",
    "        ax.set_title(case_dict[case], fontsize=13)\n",
    "        for itick,tick in enumerate(ax.get_yticklabels()):\n",
    "            if itick==0:\n",
    "                tick.set_verticalalignment(\"baseline\")\n",
    "        ax.set_ylim(0,1.04)\n",
    "        ax.set_ylabel(METRIC, fontsize=13)\n",
    "        ax.set_xlabel('# Subjects', fontsize=13)\n",
    "        # ax.set_xticklabels([\"HE\\n42 subjects\\n108 ID'd metabolites\",\"CDI\\n47 subjects\\n1005 ID'd metabolites\",\n",
    "        #             \"ERAWIJANTARI\\n96 subjects\\n511 ID'd metabolites\",\"LLOYD-PRICE\\n105 subjects\\n290 ID'd metabolites\",\n",
    "        #             \"FRANZOSA\\n155 subjects\\n232 ID'd metabolites\",\"WANG\\n287 subjects\\n156 ID'd metabolites\"])\n",
    "        # if case=='both':\n",
    "        #             f.legend(loc='lower center', bbox_to_anchor=(0.5,-0.6\n",
    "        #                                             ), ncol=len(ax.lines), fontsize=14, frameon=False)\n",
    "        # else:\n",
    "        f.legend(loc='lower center', bbox_to_anchor=(0.5,-0.6\n",
    "                                                        ), ncol=len(ax.lines), fontsize=14, frameon=False)\n",
    "\n",
    "        fig.subplots_adjust(bottom=0.2)\n",
    "        # sns.catplot(data=stacked, x='Dataset',y=METRIC,hue='Method', dodge=True, legend=False, ax=ax, edgecolor='k',linewidth=1) \n",
    "        # sns.catplot(kind=\"box\",data=stacked, x='Dataset',y=METRIC,hue='Method',ax=ax, showfliers=False,saturation=0.75)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(figpath + f'{case}_{METRIC}.jpeg', format='jpeg', dpi=600, transparent=True, bbox_inches=\"tight\")\n",
    "        # fig.savefig(f'/Users/jendawk/Dropbox (MIT)/MDITRE-Metabolites Paper/paper_figures/Fig2_SemiSynBenchmarking/{case}_{METRIC}.pdf',\n",
    "        #    transparent=True)\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        sctest={}\n",
    "        keys[case]=[]\n",
    "        ps[case]=[]\n",
    "        fdr={}\n",
    "        pdr={}\n",
    "        ls = list(dat[method].keys())\n",
    "        ls.sort()\n",
    "        ls = datasets\n",
    "        for ns in ls:\n",
    "            fdr[ns]={}\n",
    "            pdr[ns]={}\n",
    "            keys[case]=[]\n",
    "            ps[case]=[]\n",
    "            try:\n",
    "                alld = [dd['medians'][m][ns] for m in dd['medians'].keys()]\n",
    "                methods = [m for m in dd['medians'].keys()]\n",
    "                best_method = methods[np.argmax(alld)]\n",
    "                best[ns]=best_method\n",
    "            except:\n",
    "                continue\n",
    "            for vs in itertools.combinations(order,2):\n",
    "                \n",
    "                # try:\n",
    "                if vs[0]==best_method or vs[1]==best_method:\n",
    "                # alld = [dd['medians'][m][ns] for m in dd['medians'].keys()]\n",
    "                # if dd['medians'][vs[0]][ns]==max(alld) or dd['medians'][vs[1]][ns]==max(alld):\n",
    "                # if vs[0]=='MMETHANE' or vs[1]=='MMETHANE':\n",
    "                    tmp = st.mannwhitneyu(dat[vs[0]][ns], dat[vs[1]][ns]) \n",
    "                    # pvals.append(tmp.pvalue)\n",
    "                    \n",
    "                    # perm = st.PermutationMethod()\n",
    "                    # tmp = st.ranksums(dat[vs[0]][ns], dat[vs[1]][ns])\n",
    "                    # sctest[method][f'{vs[0]} vs {vs[1]}'] = tmp.pvalue\n",
    "                    keys[case].append((vs[0],vs[1]))\n",
    "                    ps[case].append(tmp.pvalue)\n",
    "                # except:\n",
    "                #     continue\n",
    "\n",
    "            if len(ps[case])>0:\n",
    "                _, corr, _, _ = multipletests(ps[case], alpha=0.05, method='fdr_bh', maxiter=-1)\n",
    "                for i,key in enumerate(keys[case]):   \n",
    "                    pdr[ns][f'{key[0]} vs {key[1]}'] = ps[case][i]\n",
    "                    # print(corr[i])\n",
    "                    fdr[ns][f'{key[0]} vs {key[1]}'] = corr[i]\n",
    "                    \n",
    "            else:\n",
    "                fdr={}\n",
    "        print(case, METRIC)\n",
    "        print(pd.Series(best).T)\n",
    "        print(pd.DataFrame(pdr))\n",
    "        pd.DataFrame(pdr).to_csv(f'{METRIC}_{fname}_{case}_significance.csv')\n",
    "        if not os.path.isdir(figdata_path):\n",
    "            os.mkdir(figdata_path)\n",
    "\n",
    "        pd.DataFrame(pdr).to_csv(figdata_path + f'{METRIC}_{fname}_{case}_significance.csv')\n",
    "        pd.DataFrame(tb).to_csv(figdata_path + f'{METRIC}_{fname}_{case}_data.csv')\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df.index = pd.DataFrame(dd['medians']).columns.values\n",
    "        # datasets = []\n",
    "        # dadict = {'he': 'HE', 'cdi':'DAWKINS', 'erawijantari': 'ERAWIJANTARI','ibmdb':'LLOYD-PRICE','franzosa':'FRANZOSA','wang':'WANG'}\n",
    "        df_ls = []\n",
    "        for dataset in datasets:\n",
    "            m = np.char.array(pd.DataFrame(dd['medians']).loc[dataset].T.apply(lambda x: np.round(x, 3)))\n",
    "            l = np.char.array(pd.DataFrame(dd['5%']).loc[dataset].T.apply(lambda x: np.round(x, 3)))\n",
    "            u = np.char.array(pd.DataFrame(dd['95%']).loc[dataset].T.apply(lambda x: np.round(x, 3)))\n",
    "            df[f'{dataset}'] = (m + b' [' + l + b', ' + u + b']').astype(str)\n",
    "        df = df.T\n",
    "        if 'AdaBoost' not in df.columns.values:\n",
    "            df['AdaBoost'] = [np.nan]*df.shape[0]\n",
    "        if append:\n",
    "            with open(f'{METRIC}_{fname}.csv','a') as f:\n",
    "                df_blank = pd.DataFrame([['']*df.shape[1]])\n",
    "                df_blank.to_csv(f, header=None, index=None)\n",
    "                pd.DataFrame([[case]*df.shape[1]]).to_csv(f, header=None, index=[0])\n",
    "                df[order].to_csv(f)\n",
    "        else:\n",
    "            with open(f'{METRIC}_{fname}.csv','w') as f:\n",
    "                pd.DataFrame([[case]*df.shape[1]]).to_csv(f, header=None, index=[0])\n",
    "            with open(f'{METRIC}_{fname}.csv','a') as f:\n",
    "                df[order].to_csv(f)\n",
    "            \n",
    "            append=True\n",
    "        # try:\n",
    "        #     df.loc[order].T.to_csv(f'{case}_{METRIC}.csv')\n",
    "        # except:\n",
    "        #     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_arm",
   "language": "python",
   "name": "py311_arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
